{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The source code and the article could be found\n",
    "here : https://towardsdatascience.com/a-gentle-introduction-to-self-training-and-semi-supervised-learning-ceee73178b38\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "__path = '../../resources/data/Surgical-deepnet.zip'\n",
    "__member = 'Surgical-deepnet.csv'\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    # Load data\n",
    "    with ZipFile(__path, 'r') as zip_file:\n",
    "        file = zip_file.extract(__member)\n",
    "    df = pd.read_csv(file)\n",
    "    # Get more informantions about the dataset.\n",
    "    #df.info()\n",
    "    os.remove(file)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preparing_dataset(df):\n",
    "    # Shuffle the data\n",
    "    df = df.sample(frac=1, random_state=15).reset_index(drop=True)\n",
    "\n",
    "    # Generate indices for splits\n",
    "    test_ind = round(len(df)*0.25)\n",
    "    train_ind = test_ind + round(len(df)*0.01)\n",
    "    unlabeled_ind = train_ind + round(len(df)*0.74)\n",
    "\n",
    "    # Partition the data\n",
    "    test = df.iloc[:test_ind]\n",
    "    train = df.iloc[test_ind:train_ind]\n",
    "    unlabeled = df.iloc[train_ind:unlabeled_ind]\n",
    "\n",
    "    # Assign data to train, test, and unlabeled sets\n",
    "    X_train = train.drop('complication', axis=1)\n",
    "    y_train = train.complication\n",
    "    X_unlabeled = unlabeled.drop('complication', axis=1)\n",
    "    X_test = test.drop('complication', axis=1)\n",
    "    y_test = test.complication\n",
    "\n",
    "    # Check dimensions of data after splitting\n",
    "    print(\"Check dimensions of data after splitting\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(f\"X_train dimensions: {X_train.shape}\")\n",
    "    print(f\"y_train dimensions: {y_train.shape}\\n\")\n",
    "    print(f\"X_test dimensions: {X_test.shape}\")\n",
    "    print(f\"y_test dimensions: {y_test.shape}\\n\")\n",
    "    print(f\"X_unlabeled dimensions: {X_unlabeled.shape}\")\n",
    "\n",
    "    # Visualize class distribution\n",
    "    y_train.value_counts().plot(kind='bar')\n",
    "    plt.xticks([0,1], ['No Complication', 'Complication'])\n",
    "    plt.ylabel('Count')\n",
    "    return X_train, y_train, X_test, y_test, X_unlabeled\n",
    "\n",
    "\n",
    "def train_labeled_data(X_train, y_train, X_test, y_test):\n",
    "    # Logistic Regression Classifier\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_hat_test = clf.predict(X_test)\n",
    "    y_hat_train = clf.predict(X_train)\n",
    "    train_f1 = f1_score(y_train, y_hat_train)\n",
    "    test_f1 = f1_score(y_test, y_hat_test)\n",
    "\n",
    "    print(f\"Train f1 Score: {train_f1}\")\n",
    "    print(f\"Test f1 Score: {test_f1}\")\n",
    "\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, cmap=plt.cm.Blues, normalize='true', display_labels=['No Comp.', 'Complication']);\n",
    "    print(\"Confusion matrix\")\n",
    "    print(disp.confusion_matrix)\n",
    "    # Generate probabilities for each prediction\n",
    "    clf.predict_proba(X_test)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def generate_pseudo_label(clf, X_train, y_train, X_test, y_test, X_unlabeled):\n",
    "    # Initiate iteration counter\n",
    "    iterations = 0\n",
    "\n",
    "    # Containers to hold f1_scores and # of pseudo-labels\n",
    "    train_f1s = []\n",
    "    test_f1s = []\n",
    "    pseudo_labels = []\n",
    "\n",
    "    # Assign value to initiate while loop\n",
    "    high_prob = [1]\n",
    "\n",
    "    # Loop will run until there are no more high-probability pseudo-labels\n",
    "    while len(high_prob) > 0:\n",
    "        # Fit classifier and make train/test predictions\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_hat_train = clf.predict(X_train)\n",
    "        y_hat_test = clf.predict(X_test)\n",
    "\n",
    "        # Calculate and print iteration # and f1 scores, and store f1 scores\n",
    "        train_f1 = f1_score(y_train, y_hat_train)\n",
    "        test_f1 = f1_score(y_test, y_hat_test)\n",
    "        #print(f\"Iteration {iterations}\")\n",
    "        #print(f\"Train f1: {train_f1}\")\n",
    "        #print(f\"Test f1: {test_f1}\")\n",
    "        train_f1s.append(train_f1)\n",
    "        test_f1s.append(test_f1)\n",
    "\n",
    "        # Generate predictions and probabilities for unlabeled data\n",
    "        #print(f\"Now predicting labels for unlabeled data...\")\n",
    "\n",
    "        pred_probs = clf.predict_proba(X_unlabeled)\n",
    "        preds = clf.predict(X_unlabeled)\n",
    "        prob_0 = pred_probs[:,0]\n",
    "        prob_1 = pred_probs[:,1]\n",
    "\n",
    "        # Store predictions and probabilities in dataframe\n",
    "        df_pred_prob = pd.DataFrame([])\n",
    "        df_pred_prob['preds'] = preds\n",
    "        df_pred_prob['prob_0'] = prob_0\n",
    "        df_pred_prob['prob_1'] = prob_1\n",
    "        df_pred_prob.index = X_unlabeled.index\n",
    "\n",
    "        # Separate predictions with > 99% probability\n",
    "        high_prob = pd.concat([df_pred_prob.loc[df_pred_prob['prob_0'] > 0.99],\n",
    "                               df_pred_prob.loc[df_pred_prob['prob_1'] > 0.99]],\n",
    "                              axis=0)\n",
    "        #print(f\"{len(high_prob)} high-probability predictions added to training data.\")\n",
    "        pseudo_labels.append(len(high_prob))\n",
    "\n",
    "        # Add pseudo-labeled data to training data\n",
    "        X_train = pd.concat([X_train, X_unlabeled.loc[high_prob.index]], axis=0)\n",
    "        y_train = pd.concat([y_train, high_prob.preds])\n",
    "\n",
    "        # Drop pseudo-labeled instances from unlabeled data\n",
    "        X_unlabeled = X_unlabeled.drop(index=high_prob.index)\n",
    "        #print(f\"{len(X_unlabeled)} unlabeled instances remaining.\\n\")\n",
    "\n",
    "        # Update iteration counter\n",
    "        iterations += 1\n",
    "    # Plot f1 scores and number of pseudo-labels added for all iterations\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(6,8))\n",
    "    ax1.plot(range(iterations), test_f1s)\n",
    "    ax1.set_ylabel('f1 Score')\n",
    "    ax2.bar(x=range(iterations), height=pseudo_labels)\n",
    "    ax2.set_ylabel('Pseudo-Labels Created')\n",
    "    ax2.set_xlabel('# Iterations');\n",
    "    return clf, X_test, y_test\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(clf,X_test, y_test):\n",
    "    # View confusion matrix after self-training\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, cmap=plt.cm.Blues, normalize='true',\n",
    "                                                 display_labels=['No Comp.', 'Complication']);\n",
    "    print(\"Confusion matrix\")\n",
    "    print(disp.confusion_matrix)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = load_dataset()\n",
    "    X_train, y_train, X_test, y_test, X_unlabeled = preparing_dataset(df)\n",
    "    clf = train_labeled_data(X_train, y_train, X_test, y_test)\n",
    "    clf, X_test, y_test = generate_pseudo_label(clf, X_train, y_train, X_test, y_test, X_unlabeled)\n",
    "    plot_confusion_matrix(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}